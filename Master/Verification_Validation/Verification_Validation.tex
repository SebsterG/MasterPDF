\chapter{Verification and Validation of the Fluid-Structure Interaction Implementation}\label{chap:VV}
When investigating a real world problem with a numerical model, the general approach is to: describe the problem with a mathematical model, discretize and implement the model on a computer, and finally simulate the implemented model to gain insight into the real world problem.

A question then immediately arises, computer models have been known to be incorrect in the past \cite{oberkampf2008verification}, how can we trust the insight gained from numerical simulation? 
To answer this question we need to adres another question, are the equations implemented correct? If so, is the mathematical description of the problem adequately defined? 
Without answering these questions, being confident that your solutions are correct is difficult \cite{oberkampf2008verification}. The process of generating evidence that computed solutions meets certain requirements to fulfill an intended purpose, in the context of scientific computing, is known as Verification and Validation. The goal of this section will hence be to verify and validate the different numerical schemes outlined in the two previous chapters.  \\

The chapter starts with the process of Verification, where the fluid and structure numerical schemes will be verified separately. Then use a well known benchmark to validate the fluid, structure, and FSI models, separately. \newline

\section{Verification}
Verification, in the context of scientific computing, is the process of determining wether or not the implementation of numerical algorithms in computer code, is correct \cite{Oberkampf2010}.
Mapping a mathematical model to a computational model there will always be introduced an error, often referred to as truncation error. Verification helps us identify, quantify, and reduce the errors, assuring that there are no coding mistakes which effects the truncation error. Verification does not address wether or not the computed solutions are in alignment with physics in the real world. It only tells us that our model is computed correctly or not. \newline

In Verification there are multiple classes of test that can be performed, one of which is \textit{order of convergence tests}. Order of convergence are based on the behavior of the error between a known exact solution and a computed solution \cite{Roache2002}. The most rigorous of the order of convergence test is the \textit{Method of Manufactured Solution} (MMS) \cite{Oberkampf2010}. When performing a Ms test, rather than looking for an exact solution, we manufacture one. The idea is to create a solution \textit{a priori}, and use this solution to generate an analytical source term for the governing PDEs and then compute the PDE with the source term to produce a solution. The manufactured solution does not need to have a physically realistic relation, since the solution is only testing the mathematics. \newline

When manufacturing a solution in MMS tests there are a number of criteria that needs to be met for a solution to be sufficient. The manufactured solutions should be chosen to be non-trivial and analytic \cite{Oberkampf2010, Roache2002}. The solutions should be manufactured such that all terms of the equation are of the same order of magnitude. For this reason trigonometric and exponential functions can be a smart choice, since they are smooth and infinitely differentiable. In short, a good manufactured solution is one that is complex enough so that it rigorously tests each part of the equations.\newline 

The procedure of MMS is as follows \cite{Oberkampf2010}:
\begin{itemize}
\item We define a mathematical model on the form $ L(\bold{u}) = 0$, where $L(\bold{u})$ is a differential operator and $u$ is a dependent variable.
\item Define the analytical form of the manufactured solution $\hat{\bold{u}}$
\item Use the model $L(u)$ with $\hat{\bold{u}}$ inserted to obtain an analytical source term $ f = L(\hat{\bold{u}}) $
\item Initial and boundary conditions are enforced from $\hat{\bold{u}}$
\item Find the numerical solution of the problem with the given source term, $L(\bold{u}) = f $
\end{itemize}

If we let $\bold{u}$ be the numerical solution and $\hat{\bold{u}}$ be the exact solution, $|| . ||$ be the $L^2$ norm, the error can be computed as:
\begin{equation}
E = || \bold{u} - \hat{\bold{u}} ||
\end{equation}
When we decrease the node spacing ($ \Delta x $) or decrease time step size($\Delta t$), we expect the solution to convergence towards a given solution and hence the error becomes smaller. If we assume uniform node spacing in all spatial directions: 
\begin{equation}
\label{eq:Error}
 E = C_1 \Delta x^k+ C_2 \Delta t^l 
\end{equation}
where $C_1$ and $C_2$ are constants, $ k = m+1 $ and m is the polynomial degree of the spatial elements. The error is hence dependent on the node spacing and the time step.
In order to compute the convergence k  based on the error, we first have to let the term with $C_2\Delta t^l$ be negligible compared to $C_1\Delta x^2$. 
Let $E_{n+1}$ and $E_{n}$ be the computed errors of a solution with fine and coarse node spacing respectively.
Using \eqref{eq:Error} we can find $k$ by:
\begin{align}
\frac{E_{n+1}}{E_n} = \big( \frac{\Delta x_{n+1}}{\Delta x_n} \big)^k \\
k = \frac{log( \frac{E_{n+1}}{E_n}) }{ log(\frac{\Delta x_{n+1}}{\Delta x_n})}
\end{align}
After refining the mesh while keeping $\Delta t $ fixed and sufficiently small,
$k$ can be compared to the theoretical order of convergence for each given problem. If the k that we have found matches the theoretical order of convergence, with small margin of error, there are no coding mistakes present which effects the order of convergence, and thus the accuracy of the numerical scheme. \newline


\input{./Verification_Validation/MMS_FSI/MMS_FSI}

\section{Validation}
After the code has been verified, we move on to Validation which is the process of determining if a model gives an accurate representation of real world physics within the bounds of the intended use \cite{oberkampf2008verification}. Depending on the quantities of interest and the problem at hand the computational model has to be validated. However, when solving a multiphysics problem, good benchmarks and trustworthy experimental data might be difficult to produce \cite{Macal2005}. Therefore we will here validate the solver, \textsl{brick by brick}, starting with simple testing of each part of the model and building more complexity and eventually testing the entire model.\newline

\begin{comment}
Three aspects have been identified in the process of validating a computational model \cite{oberkampf2008verification}. These are: quantifying the accuracy of the model by comparing responses with experimental responses, interpolation of the model to conditions corresponding to the intended use and determining the accuracy of the model for the conditions under which its meant to be used. \newline
\end{comment}

In the benchmarks used for validation, there are 9 different tests. For each test a refinement with respect to temporal an spatial resolution is performed. However, one major draw back is that the results of the benchmark were known a priori. It is easier to mold the model to the data we already have, and as Oberkampf and Trucano in \cite{oberkampf2008verification} puts it \say{Knowing the \say{correct} answer beforehand is extremely seductive, even to a saint}. Knowing the limitations of our tests will therefore strengthen our confidence in the model. The process of verifying and validating, if one does not clearly know the bounds of sufficient accuracy, is an endless process \cite{oberkampf2008verification}. 

\input{./Verification_Validation/Hron_Turek/Hron_Turek}
%\input{./Verification_Validation/Flexible_tube/Flexible_tube}











