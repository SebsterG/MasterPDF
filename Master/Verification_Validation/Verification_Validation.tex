\chapter{Verification and validation. }
When we set out to solve a real world problem with numerical computing, we start by defining the mathematics, we implement the equations numerically and solve on a computer. We then use the solutions to extract data that will answer the questions of the problem we set out so solve. A problem then immediately arises, is this solution correct? To answer this we need to answer another question, is the problem defined correct mathematically, and if so are these equations solved correct numerically? Without answering these questions, being confident that your solutions are correct is difficult. \cite{Selin2014} The goal of this section will hence be to verify and validate the different numerical schemes. \\
We start with Verification, which is the process of assessing numerical correctness and accuracy of a computed solution. Then comes Validation, which is assessing physical accuracy of the numerical model, a process which is done by comparing numerical simulation with experimental data or so called benchmark tests.


\section{Verification}
In verification we get evidence that the numerical model derived from mathematics is solved correctly by the computer. The strategy will be to identify, quantify and reduce errors cause by mapping a mathematical model to a computational model. This does not address wether or not the mathematical model is in alignment with the real world only that our model is computed correctly.
In verifying the code, order of convergence tests will be the most rigorous. To do this test we will use the method of manufactured solutions (MMS) \cite{Roache2002}. This method entails manufacturing an exact solution that is non trivial but analytic. The solution defines the boundary conditions and is passed through the equations giving a source term, named $f$. This source term is set to equalize the given equation, and then a solution is calculated. If the calculation is correct our calculated solution should equal the manufactured solution down to a give precision, computers are only precise to about $10^{-16}$. We can then increase for instance the number of cells in our computational domain, and see if the difference between the manufactured and computed solution (eg. error) gets smaller. The rate at which the error reduces can be checked with mathematical theory, we can than be more confident that our computation is correct. This will also be done in time, by reducing the time steps and investigating the error. The manufactured solution does not have to have any physical relation, and this fact does not implicate a less accurate verification. The solution needs only be non-trivial.

After the solution has been computed we perform systematic convergence tests \cite{Roache}. The idea of order of convergence test is based on the behavior of the error between the manufactured exact solution and the computed solution. When we increase the number of spatial points or decrease timestep, we expect the error to get smaller. Its the rate of this error that lets us now wether the solution is converging and hence that we are computing in the right fashion.
If we assume that the number of spatial points are equal in all directions we know that the error behaves like
$$ E = C_1 \Delta x^k+ C_2 \Delta t^l $$
where $ k = m+1 $ and m is the polynomial degree of the spatial elements. This means that when we compute with Taylor-Hood elements (P2-P1) we should expect to get a convergence rate of 2 in space and 1 in time.\
The convergence rates are computed as:
\begin{align}
\frac{E_{n+1}}{E_n} = \big( \frac{\Delta x_n+1}{\Delta x_n} \big)^k \\
k = \frac{log( \frac{E_{n+1}}{E_n}) }{ log(\frac{\Delta x_n+1}{\Delta x_n})}
\end{align}


\input{./Verification_Validation/MMS_FSI/MMS_FSI}


\section{Validation}
After the code has been verified to see that we are indeed computing in the right fashion. We move on to Validation which is the process of determining if the model gives an accurate representation of the real world within the bounds of the intended use \cite{Selin2014}. A model is made for a specific purpose, its only valid in respect to that purpose \cite{Macal2005}. If the purpose is complex and trying to answer multiple question then the validity need to be determined to each question. The idea is to validate the solver \textsl{brick by brick}. We start with simple testing of each part of the model and build more complexity and eventually testing the whole model.Three issues have been identified in this process \cite{Selin2014}: Quantifying the accuracy of the model by comparing responses with experimental responses, interpolation of the model to conditions corresponding to the intended use and determining the accuracy of the model for the conditions under which its meant to be used.  For example if our solver needs to model fluid which is turbulent we have to validate our model to catch these turbulences and as we shall see later the Taylor-Green benchmark is a good test. Well known benchmarks will be used as validation, we will see in this chapter that these tests supply us with a problem setup, initial and boundary conditions, and lastly results that we can compare with. The process of Validation is also, as I have experienced, a way to figure out at what size timestep and number of spatial points the model can handle to run. As we will see in the chapter all the benchmarks are run with different timesteps and number of cells to see how it reacts. The problem with using benchmarks with known data for comparison is that we do not test the model blindly. It is easier to mold the model to the data we already have. As Oberkampf and Trucano in \cite{Selin2014} puts it ``Knowing the ``correct" answer beforehand is extremely seductive, even to a saint.''. Knowing the limitations of our tests will therefore strengthen our confidence in the model. It really can be an endless process of verifying and validating if one does not clearly now the bounds of sufficient accuracy. 

\cite{Selin2014} \\
In the following we will look at tests for the fluid solvers both alone, testing laminar to turbulent flow, and with solid. We will test the solid solver, and lastly the entire coupled FSI problem. 
\subsection{Taylor-Green vortex}
The Taylor-Green vortex problem is used to examine if our N-S code has the ability to correctly simulate vortex decay and turbulence \cite{DeBonis2013}.
\subsubsection{Problem definition}
Using a cube with sides $2\pi$. \newline
We have an initial distribution of velocity $\bar{u} = (u,v,w)$:
\begin{align}
u(x,y,z) &= V_0sin(x)cos(y)cos(z) \\
v(x,y,z) &= - V_0cos(x)sin(y)cos(z)  \\
w(x,y,z) &= 0  
\end{align}
The Reynolds number is defined as: $Re = \frac{V_0 L}{\nu}$ where we set $V_0 = 1$


\input{./Verification_Validation/Hron_Turek/Hron_Turek}









